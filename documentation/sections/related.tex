\documentclass[../main]{subfiles}

\begin{document}


When applying the GAN architecture to the textual domain, the main hurdle to overcome is how to handle the value space of text-based data  \cite{tevet2018evaluating}.  Compared to the continuous image space GANs were originally intended for,  textual symbols are discrete and thus non-differentiable. This poses a major problem during training, as gradient backpropagation is no longer meaningfully possible \cite{gan2vec}. There are multiple proposed workarounds to this issue, such as pre-training the model with Maximum Likelihood Estimation \cite{shang-etal-2015-neural}.  Other approaches are to make use of Reinforcement Learning Strategies or Word Embeddings.

\subsection{SeqGAN \cite{seqgan}}
A well-known example of a GAN architecture with Reinforcement Learning Properties is the SeqGAN model proposed in 2017.  The generation problem in SeqGAN is posed as a reinforcement problem, with the generator aiming to maximize the expected reward of a generated sentence given by the discriminator.  The more plausible the sentence, the higher the reward. However, the generator does not produce a full sequence immediately. Instead, it samples the next token and then enacts a Monte Carlo Search over the rolled-out policy gradient to calculate the expected reward of a sequence. \cite{Wang2019}

\subsection{GAN2Vec \cite{gan2vec}}
A different solution to the task is the GAN2Vec architecture, proposed in 2019.  The objective of the generator is not to create sentences in a human-readable discrete format, but rather to generate Word2Vec embeddings. This overcomes the hurdle of discrete spaces, as the resulting vectors are no longer one-hot vectors but continuous embedding vectors.  The paper also proposes a modification to GAN2Vec which allows for an additional conditional parameter to be given to the model, such that it is possible to generate text accordingly.

\end{document}